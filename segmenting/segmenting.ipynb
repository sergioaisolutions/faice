{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## IMPORTING THE REQUIRED LIBRARIES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## IMPORTING THE DATAFRAME OF THE FACES IMAGES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def importData(path: str) -> pd.DataFrame:\r\n",
    "    return pd.read_csv(path)\r\n",
    "\r\n",
    "faces = importData('../preprocessing/data/facesDataClean.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CONVERTING THE PIXELS COLUMNS TO AN ARRAY OF PIXELS BEFORE SEGMENTING THE IMAGES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def formatPixels(pixels: str) -> list:\r\n",
    "    return [int(pixel) for pixel in pixels.split()]\r\n",
    "\r\n",
    "faces['pixels'] = faces['pixels'].apply(formatPixels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SEGMENTING THE IMAGES PER AGE, ETHNICITY AND GENDER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def saveImage(name: str, pixels: list, path: str):\r\n",
    "    \r\n",
    "    pixelsArray = np.array(pixels)\r\n",
    "    pixelsArrayReshaped = np.asarray(pixelsArray, dtype = np.uint8).reshape(48, 48)\r\n",
    "    \r\n",
    "    return plt.imsave(fname = f'{path}/{name}', arr = pixelsArrayReshaped, format = 'jpg')\r\n",
    "\r\n",
    "for imageName, imagePixels, imageAge, imageEthnicity, imageGender in zip(faces['img_name'], faces['pixels'], faces['age_bin'], \r\n",
    "                                                                         faces['ethnicity'], faces['gender']):\r\n",
    "\r\n",
    "    if imageAge == '1-18':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/age/1-18')\r\n",
    "    elif imageAge == '19-35':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/age/19-35')\r\n",
    "    elif imageAge == '36-60':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/age/36-60')\r\n",
    "    else:\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/age/+60')\r\n",
    "\r\n",
    "    if imageEthnicity == 'White':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/ethnicity/white')\r\n",
    "    elif imageEthnicity == 'Black':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/ethnicity/black')\r\n",
    "    elif imageEthnicity == 'Asian':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/ethnicity/asian')\r\n",
    "    elif imageEthnicity == 'Indian':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/ethnicity/indian')\r\n",
    "    else:\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/ethnicity/hispanic')\r\n",
    "\r\n",
    "    if imageGender == 'Male':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/gender/male')\r\n",
    "    elif imageGender == 'Female':\r\n",
    "        saveImage(imageName, imagePixels, '../data/facesImages/gender/female')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "349ec2ade89aee60c3e53de8965ee4c718834e5923df1877d1daea78ab99660b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}